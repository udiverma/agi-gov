{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pandas ollama datetime Bio google transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h61sNivnxrah",
        "outputId": "f2539cde-146d-4c67-debb-275ef786485c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: ollama in /usr/local/lib/python3.10/dist-packages (0.4.7)\n",
            "Requirement already satisfied: datetime in /usr/local/lib/python3.10/dist-packages (5.5)\n",
            "Requirement already satisfied: Bio in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.50.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.10/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from ollama) (2.10.3)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.10/dist-packages (from datetime) (7.2)\n",
            "Requirement already satisfied: biopython>=1.80 in /usr/local/lib/python3.10/dist-packages (from Bio) (1.85)\n",
            "Requirement already satisfied: gprofiler-official in /usr/local/lib/python3.10/dist-packages (from Bio) (1.0.0)\n",
            "Requirement already satisfied: mygene in /usr/local/lib/python3.10/dist-packages (from Bio) (3.2.2)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from Bio) (1.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from Bio) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from Bio) (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from google) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.29,>=0.27->ollama) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.29,>=0.27->ollama) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->google) (2.6)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from mygene->Bio) (0.4.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (4.3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2.2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime) (75.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from Bio import Entrez, SeqIO\n",
        "import urllib.request\n",
        "import gzip\n",
        "from io import BytesIO\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from googlesearch import search\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from itertools import product\n",
        "import difflib\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn.functional as F\n",
        "import transformers_modules\n"
      ],
      "metadata": {
        "id": "ogPqNA6KquCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgjh6krquZYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d36c3b-6c3e-40f8-c236-ec3f1cb29b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Assembly               Organism_Name                     Species  \\\n",
            "0  GCF_029888495.1                  Yezo virus    Orthonairovirus yezoense   \n",
            "1  GCF_029888155.1            Beiji nairovirus            Beiji nairovirus   \n",
            "2  GCF_029888075.1              Songling virus              Songling virus   \n",
            "3  GCF_018595055.1  Dar es Salaam virus TZ-189  Tanzavirus daressalaamense   \n",
            "4  GCF_013086615.1                 Cocle virus       Phlebovirus cocleense   \n",
            "\n",
            "             Genus         Family  \n",
            "0  Orthonairovirus   Nairoviridae  \n",
            "1  Orthonairovirus   Nairoviridae  \n",
            "2  Orthonairovirus   Nairoviridae  \n",
            "3       Tanzavirus  Phenuiviridae  \n",
            "4      Phlebovirus  Phenuiviridae  \n",
            "70145\n"
          ]
        }
      ],
      "source": [
        "# Reads sequence database into a dataframe\n",
        "\n",
        "Entrez.email = \"your_email@example.com\"\n",
        "\n",
        "SEQUENCE_PATH = 'op/sequences_2.csv'\n",
        "\n",
        "df = pd.read_csv(SEQUENCE_PATH)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter to only 1 result per species\n",
        "\n",
        "filtered_df = df.groupby('Species', group_keys=False).head(1)\n",
        "\n",
        "print(filtered_df.head())\n",
        "\n",
        "print(len(filtered_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j13UmyJSx2XE",
        "outputId": "3118749a-cf29-475d-f95c-07bd515de632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Assembly               Organism_Name                     Species  \\\n",
            "0  GCF_029888495.1                  Yezo virus    Orthonairovirus yezoense   \n",
            "1  GCF_029888155.1            Beiji nairovirus            Beiji nairovirus   \n",
            "2  GCF_029888075.1              Songling virus              Songling virus   \n",
            "3  GCF_018595055.1  Dar es Salaam virus TZ-189  Tanzavirus daressalaamense   \n",
            "4  GCF_013086615.1                 Cocle virus       Phlebovirus cocleense   \n",
            "\n",
            "             Genus         Family  \n",
            "0  Orthonairovirus   Nairoviridae  \n",
            "1  Orthonairovirus   Nairoviridae  \n",
            "2  Orthonairovirus   Nairoviridae  \n",
            "3       Tanzavirus  Phenuiviridae  \n",
            "4      Phlebovirus  Phenuiviridae  \n",
            "203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for getting viral data from the accession number\n",
        "\n",
        "Entrez.email = \"sir.peepster@gmail.com\"\n",
        "\n",
        "def get_viral_data(assembly, genome_dir=\"op/sequences\", annotation_dir=\"op/annotations\"):\n",
        "    '''\n",
        "    Given an assembly accession (e.g. GCF_029888495.1),\n",
        "    fetches and parses the genome and annotation data from NCBI,\n",
        "    and saves them into separate folders.\n",
        "\n",
        "    Returns a dict with:\n",
        "    - genome: str (raw sequence)\n",
        "    - annotations: list of dicts\n",
        "    - paths to saved files\n",
        "    '''\n",
        "    os.makedirs(genome_dir, exist_ok=True)\n",
        "    os.makedirs(annotation_dir, exist_ok=True)\n",
        "\n",
        "    genome_txt = os.path.join(genome_dir, f\"{assembly}.txt\")\n",
        "    annotation_csv = os.path.join(annotation_dir, f\"{assembly}.csv\")\n",
        "\n",
        "    # Skip if both files already exist\n",
        "    if os.path.exists(genome_txt) and os.path.exists(annotation_csv):\n",
        "        print(f\"[SKIP] {assembly} already processed.\")\n",
        "        return {\n",
        "            \"genome_file\": genome_txt,\n",
        "            \"annotation_file\": annotation_csv,\n",
        "            \"skipped\": True\n",
        "        }\n",
        "\n",
        "    # Search assembly UID\n",
        "    search_handle = Entrez.esearch(db=\"assembly\", term=assembly, retmode=\"xml\")\n",
        "    search_results = Entrez.read(search_handle)\n",
        "    search_handle.close()\n",
        "\n",
        "    if not search_results['IdList']:\n",
        "        raise ValueError(f\"Assembly {assembly} not found.\")\n",
        "\n",
        "    uid = search_results['IdList'][0]\n",
        "\n",
        "    # Get FTP path\n",
        "    summary_handle = Entrez.esummary(db=\"assembly\", id=uid, retmode=\"xml\")\n",
        "    summary = Entrez.read(summary_handle)\n",
        "    summary_handle.close()\n",
        "\n",
        "    doc = summary['DocumentSummarySet']['DocumentSummary'][0]\n",
        "    ftp_path = doc['FtpPath_RefSeq'] or doc['FtpPath_GenBank']\n",
        "    if not ftp_path:\n",
        "        raise ValueError(f\"No FTP path found for {assembly}\")\n",
        "\n",
        "    base = ftp_path.split(\"/\")[-1]\n",
        "    gb_url = f\"{ftp_path}/{base}_genomic.gbff.gz\"\n",
        "    print(f\"[INFO] Downloading: {gb_url}\")\n",
        "\n",
        "    # Download and parse GenBank\n",
        "    with urllib.request.urlopen(gb_url) as response:\n",
        "        with gzip.open(BytesIO(response.read()), \"rt\") as handle:\n",
        "            records = list(SeqIO.parse(handle, \"genbank\"))\n",
        "\n",
        "    if not records:\n",
        "        raise ValueError(\"No GenBank records found.\")\n",
        "\n",
        "    record = records[0]\n",
        "\n",
        "    # Save genome\n",
        "    with open(genome_txt, \"w\") as f:\n",
        "        f.write(f\">{record.id}\\n{record.seq}\")\n",
        "\n",
        "    # Parse annotations\n",
        "    annotations = []\n",
        "    for feature in record.features:\n",
        "        feat = {\n",
        "            \"type\": feature.type,\n",
        "            \"location\": str(feature.location),\n",
        "        }\n",
        "        for key, value in feature.qualifiers.items():\n",
        "            feat[key] = \"; \".join(value)\n",
        "        annotations.append(feat)\n",
        "\n",
        "    annotation_df = pd.DataFrame(annotations)\n",
        "    annotation_df.to_csv(annotation_csv, index=False)\n",
        "\n",
        "    return {\n",
        "        \"genome\": str(record.seq),\n",
        "        \"annotations\": annotations,\n",
        "        \"genome_file\": genome_txt,\n",
        "        \"annotation_file\": annotation_csv,\n",
        "        \"genbank_url\": gb_url,\n",
        "        \"skipped\": False\n",
        "    }\n"
      ],
      "metadata": {
        "id": "PHRN2J6cKT6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Playground for viral data\n",
        "\n",
        "demo_result = get_viral_data('GCF_008711635.1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVGIkdLAKXu8",
        "outputId": "0156f2e4-d010-4bce-ed89-d8b818ef1ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SKIP] GCF_008711635.1 already processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_csv = pd.read_csv('op/annotations/GCF_008711635.1.csv')\n",
        "\n",
        "print(testing_csv.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l86omDrcNPlv",
        "outputId": "cd721dd4-e315-4f66-edf5-6e60fef977a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          type     location       organism     mol_type  \\\n",
            "0       source  [0:7525](+)  Norovirus GII  genomic RNA   \n",
            "1        5'UTR     [0:4](+)            NaN          NaN   \n",
            "2         gene  [4:5095](+)            NaN          NaN   \n",
            "3          CDS  [4:5095](+)            NaN          NaN   \n",
            "4  mat_peptide  [4:1000](+)            NaN          NaN   \n",
            "\n",
            "                                 isolate isolation_source          host  \\\n",
            "0  Hu/GII.PNA4-GII.NA4/PNV06929/2008/PER            stool  Homo sapiens   \n",
            "1                                    NaN              NaN           NaN   \n",
            "2                                    NaN              NaN           NaN   \n",
            "3                                    NaN              NaN           NaN   \n",
            "4                                    NaN              NaN           NaN   \n",
            "\n",
            "           db_xref country collection_date       genotype  gene  locus_tag  \\\n",
            "0     taxon:122929    Peru     27-May-2008  GII.NA2[PNA2]   NaN        NaN   \n",
            "1              NaN     NaN             NaN            NaN   NaN        NaN   \n",
            "2  GeneID:41871946     NaN             NaN            NaN  ORF1  F7X33_gp1   \n",
            "3  GeneID:41871946     NaN             NaN            NaN  ORF1  F7X33_gp1   \n",
            "4              NaN     NaN             NaN            NaN  ORF1  F7X33_gp1   \n",
            "\n",
            "   codon_start                    product      protein_id  \\\n",
            "0          NaN                        NaN             NaN   \n",
            "1          NaN                        NaN             NaN   \n",
            "2          NaN                        NaN             NaN   \n",
            "3          1.0  nonstructural polyprotein  YP_009701445.1   \n",
            "4          NaN                        p48  YP_009701448.1   \n",
            "\n",
            "                                         translation  \n",
            "0                                                NaN  \n",
            "1                                                NaN  \n",
            "2                                                NaN  \n",
            "3  MKMASNDAATATAGTTSSNSEIHNKDVSNTQNIFANMTVGIKRALG...  \n",
            "4                                                NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in filtered_df.iterrows():\n",
        "    print(row['Assembly'])\n",
        "    get_viral_data(row['Assembly'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fsYr85ZO1HK",
        "outputId": "3a5bcde0-cdd8-4d9e-813e-0ec6bc388833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCF_029888495.1\n",
            "[SKIP] GCF_029888495.1 already processed.\n",
            "GCF_029888155.1\n",
            "[SKIP] GCF_029888155.1 already processed.\n",
            "GCF_029888075.1\n",
            "[SKIP] GCF_029888075.1 already processed.\n",
            "GCF_018595055.1\n",
            "[SKIP] GCF_018595055.1 already processed.\n",
            "GCF_013086615.1\n",
            "[SKIP] GCF_013086615.1 already processed.\n",
            "GCF_013086545.1\n",
            "[SKIP] GCF_013086545.1 already processed.\n",
            "GCF_006298385.1\n",
            "[SKIP] GCF_006298385.1 already processed.\n",
            "GCF_029887105.1\n",
            "[SKIP] GCF_029887105.1 already processed.\n",
            "GCF_024749945.1\n",
            "[SKIP] GCF_024749945.1 already processed.\n",
            "GCF_023122845.1\n",
            "[SKIP] GCF_023122845.1 already processed.\n",
            "GCF_018591295.1\n",
            "[SKIP] GCF_018591295.1 already processed.\n",
            "GCF_018584815.1\n",
            "[SKIP] GCF_018584815.1 already processed.\n",
            "GCF_018583805.1\n",
            "[SKIP] GCF_018583805.1 already processed.\n",
            "GCF_018583635.1\n",
            "[SKIP] GCF_018583635.1 already processed.\n",
            "GCF_018583605.1\n",
            "[SKIP] GCF_018583605.1 already processed.\n",
            "GCF_018580895.1\n",
            "[SKIP] GCF_018580895.1 already processed.\n",
            "GCF_018580825.1\n",
            "[SKIP] GCF_018580825.1 already processed.\n",
            "GCF_013087445.1\n",
            "[SKIP] GCF_013087445.1 already processed.\n",
            "GCF_008792745.1\n",
            "[SKIP] GCF_008792745.1 already processed.\n",
            "GCF_006370125.1\n",
            "[SKIP] GCF_006370125.1 already processed.\n",
            "GCF_003963575.1\n",
            "[SKIP] GCF_003963575.1 already processed.\n",
            "GCF_003033285.1\n",
            "[SKIP] GCF_003033285.1 already processed.\n",
            "GCF_002889255.1\n",
            "[SKIP] GCF_002889255.1 already processed.\n",
            "GCF_014621545.1\n",
            "[SKIP] GCF_014621545.1 already processed.\n",
            "GCF_013088445.1\n",
            "[SKIP] GCF_013088445.1 already processed.\n",
            "GCF_013086435.1\n",
            "[SKIP] GCF_013086435.1 already processed.\n",
            "GCF_013086425.1\n",
            "[SKIP] GCF_013086425.1 already processed.\n",
            "GCF_013086385.1\n",
            "[SKIP] GCF_013086385.1 already processed.\n",
            "GCF_006452035.1\n",
            "[SKIP] GCF_006452035.1 already processed.\n",
            "GCF_003443495.1\n",
            "[SKIP] GCF_003443495.1 already processed.\n",
            "GCF_009858895.2\n",
            "[SKIP] GCF_009858895.2 already processed.\n",
            "GCF_008711635.1\n",
            "[SKIP] GCF_008711635.1 already processed.\n",
            "GCF_004789975.1\n",
            "[SKIP] GCF_004789975.1 already processed.\n",
            "GCF_003087855.1\n",
            "[SKIP] GCF_003087855.1 already processed.\n",
            "GCF_004131685.1\n",
            "[SKIP] GCF_004131685.1 already processed.\n",
            "GCF_003727435.1\n",
            "[SKIP] GCF_003727435.1 already processed.\n",
            "GCF_003726995.1\n",
            "[SKIP] GCF_003726995.1 already processed.\n",
            "GCF_000845685.2\n",
            "[SKIP] GCF_000845685.2 already processed.\n",
            "GCF_000943645.1\n",
            "[SKIP] GCF_000943645.1 already processed.\n",
            "GCF_001712785.1\n",
            "[SKIP] GCF_001712785.1 already processed.\n",
            "GCF_003055605.1\n",
            "[SKIP] GCF_003055605.1 already processed.\n",
            "GCF_003033575.1\n",
            "[SKIP] GCF_003033575.1 already processed.\n",
            "GCF_003033495.1\n",
            "[SKIP] GCF_003033495.1 already processed.\n",
            "GCF_003033485.1\n",
            "[SKIP] GCF_003033485.1 already processed.\n",
            "GCF_003033475.1\n",
            "[SKIP] GCF_003033475.1 already processed.\n",
            "GCF_003033315.1\n",
            "[SKIP] GCF_003033315.1 already processed.\n",
            "GCF_003032765.1\n",
            "[SKIP] GCF_003032765.1 already processed.\n",
            "GCF_002987365.1\n",
            "[SKIP] GCF_002987365.1 already processed.\n",
            "GCF_002831305.1\n",
            "[SKIP] GCF_002831305.1 already processed.\n",
            "GCF_002829445.1\n",
            "[SKIP] GCF_002829445.1 already processed.\n",
            "GCF_002829425.1\n",
            "[SKIP] GCF_002829425.1 already processed.\n",
            "GCF_002820205.1\n",
            "[SKIP] GCF_002820205.1 already processed.\n",
            "GCF_002815115.1\n",
            "[SKIP] GCF_002815115.1 already processed.\n",
            "GCF_002827025.1\n",
            "[SKIP] GCF_002827025.1 already processed.\n",
            "GCF_002827045.1\n",
            "[SKIP] GCF_002827045.1 already processed.\n",
            "GCF_002827005.1\n",
            "[SKIP] GCF_002827005.1 already processed.\n",
            "GCF_002826985.1\n",
            "[SKIP] GCF_002826985.1 already processed.\n",
            "GCF_002826025.1\n",
            "[SKIP] GCF_002826025.1 already processed.\n",
            "GCF_002826005.1\n",
            "[SKIP] GCF_002826005.1 already processed.\n",
            "GCF_002821385.1\n",
            "[SKIP] GCF_002821385.1 already processed.\n",
            "GCF_002820225.1\n",
            "[SKIP] GCF_002820225.1 already processed.\n",
            "GCF_002820185.1\n",
            "[SKIP] GCF_002820185.1 already processed.\n",
            "GCF_002820165.1\n",
            "[SKIP] GCF_002820165.1 already processed.\n",
            "GCF_002820145.1\n",
            "[SKIP] GCF_002820145.1 already processed.\n",
            "GCF_002820125.1\n",
            "[SKIP] GCF_002820125.1 already processed.\n",
            "GCF_002820105.1\n",
            "[SKIP] GCF_002820105.1 already processed.\n",
            "GCF_002820065.1\n",
            "[SKIP] GCF_002820065.1 already processed.\n",
            "GCF_002819605.1\n",
            "[SKIP] GCF_002819605.1 already processed.\n",
            "GCF_002818765.1\n",
            "[SKIP] GCF_002818765.1 already processed.\n",
            "GCF_002818745.1\n",
            "[SKIP] GCF_002818745.1 already processed.\n",
            "GCF_002818725.1\n",
            "[SKIP] GCF_002818725.1 already processed.\n",
            "GCF_002818705.1\n",
            "[SKIP] GCF_002818705.1 already processed.\n",
            "GCF_002818685.1\n",
            "[SKIP] GCF_002818685.1 already processed.\n",
            "GCF_002818665.1\n",
            "[SKIP] GCF_002818665.1 already processed.\n",
            "GCF_002818645.1\n",
            "[SKIP] GCF_002818645.1 already processed.\n",
            "GCF_002818625.1\n",
            "[SKIP] GCF_002818625.1 already processed.\n",
            "GCF_002818605.1\n",
            "[SKIP] GCF_002818605.1 already processed.\n",
            "GCF_002818585.1\n",
            "[SKIP] GCF_002818585.1 already processed.\n",
            "GCF_002818565.1\n",
            "[SKIP] GCF_002818565.1 already processed.\n",
            "GCF_002818545.1\n",
            "[SKIP] GCF_002818545.1 already processed.\n",
            "GCF_002818485.1\n",
            "[SKIP] GCF_002818485.1 already processed.\n",
            "GCF_002818465.1\n",
            "[SKIP] GCF_002818465.1 already processed.\n",
            "GCF_002818245.1\n",
            "[SKIP] GCF_002818245.1 already processed.\n",
            "GCF_002816195.1\n",
            "[SKIP] GCF_002816195.1 already processed.\n",
            "GCF_002815875.1\n",
            "[SKIP] GCF_002815875.1 already processed.\n",
            "GCF_002402265.1\n",
            "[SKIP] GCF_002402265.1 already processed.\n",
            "GCF_001939215.2\n",
            "[SKIP] GCF_001939215.2 already processed.\n",
            "GCF_002820085.1\n",
            "[SKIP] GCF_002820085.1 already processed.\n",
            "GCF_002374975.1\n",
            "[SKIP] GCF_002374975.1 already processed.\n",
            "GCF_000918035.2\n",
            "[SKIP] GCF_000918035.2 already processed.\n",
            "GCF_002375055.1\n",
            "[SKIP] GCF_002375055.1 already processed.\n",
            "GCF_002366285.1\n",
            "[SKIP] GCF_002366285.1 already processed.\n",
            "GCF_002285025.1\n",
            "[SKIP] GCF_002285025.1 already processed.\n",
            "GCF_002270605.1\n",
            "[SKIP] GCF_002270605.1 already processed.\n",
            "GCF_002219885.1\n",
            "[SKIP] GCF_002219885.1 already processed.\n",
            "GCF_002219705.1\n",
            "[SKIP] GCF_002219705.1 already processed.\n",
            "GCF_002219525.1\n",
            "[SKIP] GCF_002219525.1 already processed.\n",
            "GCF_002153865.1\n",
            "[SKIP] GCF_002153865.1 already processed.\n",
            "GCF_002118905.1\n",
            "[SKIP] GCF_002118905.1 already processed.\n",
            "GCF_002118805.1\n",
            "[SKIP] GCF_002118805.1 already processed.\n",
            "GCF_002118505.1\n",
            "[SKIP] GCF_002118505.1 already processed.\n",
            "GCF_002118405.1\n",
            "[SKIP] GCF_002118405.1 already processed.\n",
            "GCF_002117635.1\n",
            "[SKIP] GCF_002117635.1 already processed.\n",
            "GCF_002080215.1\n",
            "[SKIP] GCF_002080215.1 already processed.\n",
            "GCF_002006915.1\n",
            "[SKIP] GCF_002006915.1 already processed.\n",
            "GCF_001684625.1\n",
            "[SKIP] GCF_001684625.1 already processed.\n",
            "GCF_001679875.1\n",
            "[SKIP] GCF_001679875.1 already processed.\n",
            "GCF_001679855.1\n",
            "[SKIP] GCF_001679855.1 already processed.\n",
            "GCF_001661815.1\n",
            "[SKIP] GCF_001661815.1 already processed.\n",
            "GCF_001448435.1\n",
            "[SKIP] GCF_001448435.1 already processed.\n",
            "GCF_001430115.1\n",
            "[SKIP] GCF_001430115.1 already processed.\n",
            "GCF_001343785.1\n",
            "[SKIP] GCF_001343785.1 already processed.\n",
            "GCF_001274345.1\n",
            "[SKIP] GCF_001274345.1 already processed.\n",
            "GCF_001184845.1\n",
            "[SKIP] GCF_001184845.1 already processed.\n",
            "GCF_000858385.2\n",
            "[SKIP] GCF_000858385.2 already processed.\n",
            "GCF_000989155.1\n",
            "[SKIP] GCF_000989155.1 already processed.\n",
            "GCF_000973295.1\n",
            "[SKIP] GCF_000973295.1 already processed.\n",
            "GCF_000871625.2\n",
            "[SKIP] GCF_000871625.2 already processed.\n",
            "GCF_000930495.1\n",
            "[SKIP] GCF_000930495.1 already processed.\n",
            "GCF_000930055.1\n",
            "[SKIP] GCF_000930055.1 already processed.\n",
            "GCF_000929855.1\n",
            "[SKIP] GCF_000929855.1 already processed.\n",
            "GCF_000929235.1\n",
            "[SKIP] GCF_000929235.1 already processed.\n",
            "GCF_000926235.1\n",
            "[SKIP] GCF_000926235.1 already processed.\n",
            "GCF_000924495.1\n",
            "[SKIP] GCF_000924495.1 already processed.\n",
            "GCF_000924255.1\n",
            "[SKIP] GCF_000924255.1 already processed.\n",
            "GCF_000924015.1\n",
            "[SKIP] GCF_000924015.1 already processed.\n",
            "GCF_000923215.1\n",
            "[SKIP] GCF_000923215.1 already processed.\n",
            "GCF_000922675.1\n",
            "[SKIP] GCF_000922675.1 already processed.\n",
            "GCF_000920655.1\n",
            "[SKIP] GCF_000920655.1 already processed.\n",
            "GCF_000919735.1\n",
            "[SKIP] GCF_000919735.1 already processed.\n",
            "GCF_000918175.1\n",
            "[SKIP] GCF_000918175.1 already processed.\n",
            "GCF_000918095.1\n",
            "[SKIP] GCF_000918095.1 already processed.\n",
            "GCF_000913875.1\n",
            "[SKIP] GCF_000913875.1 already processed.\n",
            "GCF_000913075.1\n",
            "[SKIP] GCF_000913075.1 already processed.\n",
            "GCF_000912535.1\n",
            "[SKIP] GCF_000912535.1 already processed.\n",
            "GCF_000912415.1\n",
            "[SKIP] GCF_000912415.1 already processed.\n",
            "GCF_000910875.1\n",
            "[SKIP] GCF_000910875.1 already processed.\n",
            "GCF_000908835.1\n",
            "[SKIP] GCF_000908835.1 already processed.\n",
            "GCF_000908695.1\n",
            "[SKIP] GCF_000908695.1 already processed.\n",
            "GCF_000906815.1\n",
            "[SKIP] GCF_000906815.1 already processed.\n",
            "GCF_000905375.1\n",
            "[SKIP] GCF_000905375.1 already processed.\n",
            "GCF_000904055.1\n",
            "[SKIP] GCF_000904055.1 already processed.\n",
            "GCF_000901475.1\n",
            "[SKIP] GCF_000901475.1 already processed.\n",
            "GCF_000899535.1\n",
            "[SKIP] GCF_000899535.1 already processed.\n",
            "GCF_000899075.1\n",
            "[SKIP] GCF_000899075.1 already processed.\n",
            "GCF_000898335.1\n",
            "[SKIP] GCF_000898335.1 already processed.\n",
            "GCF_000898255.1\n",
            "[SKIP] GCF_000898255.1 already processed.\n",
            "GCF_000897955.1\n",
            "[SKIP] GCF_000897955.1 already processed.\n",
            "GCF_000897255.1\n",
            "[SKIP] GCF_000897255.1 already processed.\n",
            "GCF_000896975.1\n",
            "[SKIP] GCF_000896975.1 already processed.\n",
            "GCF_000895575.1\n",
            "[SKIP] GCF_000895575.1 already processed.\n",
            "GCF_000891955.1\n",
            "[SKIP] GCF_000891955.1 already processed.\n",
            "GCF_000891915.1\n",
            "[SKIP] GCF_000891915.1 already processed.\n",
            "GCF_000891615.1\n",
            "[SKIP] GCF_000891615.1 already processed.\n",
            "GCF_000891495.1\n",
            "[SKIP] GCF_000891495.1 already processed.\n",
            "GCF_000890535.1\n",
            "[SKIP] GCF_000890535.1 already processed.\n",
            "GCF_000890115.1\n",
            "[SKIP] GCF_000890115.1 already processed.\n",
            "GCF_000889695.1\n",
            "[SKIP] GCF_000889695.1 already processed.\n",
            "GCF_000889675.1\n",
            "[SKIP] GCF_000889675.1 already processed.\n",
            "GCF_000889175.1\n",
            "[SKIP] GCF_000889175.1 already processed.\n",
            "GCF_000889155.1\n",
            "[SKIP] GCF_000889155.1 already processed.\n",
            "GCF_000889075.1\n",
            "[SKIP] GCF_000889075.1 already processed.\n",
            "GCF_000888975.1\n",
            "[SKIP] GCF_000888975.1 already processed.\n",
            "GCF_000888495.1\n",
            "[SKIP] GCF_000888495.1 already processed.\n",
            "GCF_000888475.1\n",
            "[SKIP] GCF_000888475.1 already processed.\n",
            "GCF_000888315.1\n",
            "[SKIP] GCF_000888315.1 already processed.\n",
            "GCF_000887495.1\n",
            "[SKIP] GCF_000887495.1 already processed.\n",
            "GCF_000887335.1\n",
            "[SKIP] GCF_000887335.1 already processed.\n",
            "GCF_000887355.1\n",
            "[SKIP] GCF_000887355.1 already processed.\n",
            "GCF_000887215.1\n",
            "[SKIP] GCF_000887215.1 already processed.\n",
            "GCF_000886535.1\n",
            "[SKIP] GCF_000886535.1 already processed.\n",
            "GCF_000886455.1\n",
            "[SKIP] GCF_000886455.1 already processed.\n",
            "GCF_000886475.1\n",
            "[SKIP] GCF_000886475.1 already processed.\n",
            "GCF_000886375.1\n",
            "[SKIP] GCF_000886375.1 already processed.\n",
            "GCF_000885815.1\n",
            "[SKIP] GCF_000885815.1 already processed.\n",
            "GCF_000885595.1\n",
            "[SKIP] GCF_000885595.1 already processed.\n",
            "GCF_000885555.1\n",
            "[SKIP] GCF_000885555.1 already processed.\n",
            "GCF_000884955.1\n",
            "[SKIP] GCF_000884955.1 already processed.\n",
            "GCF_000884395.1\n",
            "[SKIP] GCF_000884395.1 already processed.\n",
            "GCF_000882595.1\n",
            "[SKIP] GCF_000882595.1 already processed.\n",
            "GCF_000880515.1\n",
            "[SKIP] GCF_000880515.1 already processed.\n",
            "GCF_000879235.1\n",
            "[SKIP] GCF_000879235.1 already processed.\n",
            "GCF_000874865.1\n",
            "[SKIP] GCF_000874865.1 already processed.\n",
            "GCF_000870545.1\n",
            "[SKIP] GCF_000870545.1 already processed.\n",
            "GCF_000864765.1\n",
            "[SKIP] GCF_000864765.1 already processed.\n",
            "GCF_000861885.1\n",
            "[SKIP] GCF_000861885.1 already processed.\n",
            "GCF_000861005.1\n",
            "[SKIP] GCF_000861005.1 already processed.\n",
            "GCF_000860145.1\n",
            "[SKIP] GCF_000860145.1 already processed.\n",
            "GCF_000858765.1\n",
            "[SKIP] GCF_000858765.1 already processed.\n",
            "GCF_000858285.1\n",
            "[SKIP] GCF_000858285.1 already processed.\n",
            "GCF_000855585.1\n",
            "[SKIP] GCF_000855585.1 already processed.\n",
            "GCF_000854765.1\n",
            "[SKIP] GCF_000854765.1 already processed.\n",
            "GCF_000848125.1\n",
            "[SKIP] GCF_000848125.1 already processed.\n",
            "GCF_000846805.1\n",
            "[SKIP] GCF_000846805.1 already processed.\n",
            "GCF_000846685.1\n",
            "[SKIP] GCF_000846685.1 already processed.\n",
            "GCF_000846365.1\n",
            "[SKIP] GCF_000846365.1 already processed.\n",
            "GCF_000845985.1\n",
            "[SKIP] GCF_000845985.1 already processed.\n",
            "GCF_000845245.1\n",
            "[SKIP] GCF_000845245.1 already processed.\n",
            "GCF_000845085.1\n",
            "[SKIP] GCF_000845085.1 already processed.\n",
            "GCF_000841965.1\n",
            "[SKIP] GCF_000841965.1 already processed.\n",
            "GCF_000838265.1\n",
            "[SKIP] GCF_000838265.1 already processed.\n",
            "GCA_049040715.1\n",
            "[SKIP] GCA_049040715.1 already processed.\n",
            "GCA_048212775.1\n",
            "[SKIP] GCA_048212775.1 already processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "import re\n",
        "import inspect\n",
        "from ollama import ChatResponse\n",
        "from datetime import datetime\n",
        "\n",
        "def get_time():\n",
        "    return datetime.utcnow().isoformat(timespec='microseconds') + 'Z'\n",
        "\n",
        "def timestamp_to_datetime(timestamp: str):\n",
        "    # Convert ISO 8601 timestamp with 7-digit precision\n",
        "    return datetime.strptime(timestamp[:-1], \"%Y-%m-%dT%H:%M:%S.%f\")\n",
        "\n",
        "def time_difference_in_ns(timestamp1: str, timestamp2: str):\n",
        "    dt1 = timestamp_to_datetime(timestamp1)\n",
        "    dt2 = timestamp_to_datetime(timestamp2)\n",
        "\n",
        "    # Calculate the difference in seconds and convert to nanoseconds\n",
        "    delta_ns = int((dt2 - dt1).total_seconds() * 1e9)\n",
        "    return delta_ns\n",
        "\n",
        "def default_format_tool_instructions(tool_name: str, tool: callable, instructions: str):\n",
        "    # Extract parameter details from the tool\n",
        "    signature = inspect.signature(tool)\n",
        "    param_list = []\n",
        "\n",
        "    for name, param in signature.parameters.items():\n",
        "        if param.default is inspect.Parameter.empty:\n",
        "            param_list.append(name)  # Required parameter\n",
        "        else:\n",
        "            param_list.append(f\"{name}={param.default}\")  # Optional parameter with default\n",
        "\n",
        "    # Join parameters for formatting\n",
        "    param_str = ', '.join(param_list)\n",
        "\n",
        "    # Return formatted instructions\n",
        "    return f'''You have been given access to the tool \"{tool_name}({param_str})\". {instructions}\n",
        "    Please call this function by using the following format: <call tool>{tool_name}({param_str})</call tool>'''\n",
        "\n",
        "class Agent():\n",
        "    def __init__(self, model: str):\n",
        "        '''\n",
        "        Initiate the model with the model used and\n",
        "        blank memory and debug log.\n",
        "        '''\n",
        "        self.client = ollama.Client(host='http://host.docker.internal:11434')\n",
        "        self.model = model\n",
        "        self.memory = []\n",
        "        self.log = [{\n",
        "            'time': get_time(),\n",
        "            'action': '__init__',\n",
        "            'prompt': model,\n",
        "            'other': {}\n",
        "        }] # time, action, prompt, other\n",
        "        self.tools = {}\n",
        "        self.format_tool_instructions = default_format_tool_instructions\n",
        "\n",
        "    def add_tool(self, tool_name: str, tool: callable, instructions: str = None):\n",
        "        self.tools[tool_name] = {}\n",
        "        self.tools[tool_name]['tool'] = tool\n",
        "        self.tools[tool_name]['instructions'] = instructions\n",
        "        self.log.append({\n",
        "            'time': get_time(),\n",
        "            'action': 'add_tool',\n",
        "            'prompt': tool_name,\n",
        "            'other': {\n",
        "                'instructions': instructions\n",
        "            }\n",
        "        })\n",
        "        if instructions is not None:\n",
        "            self.sys_prompt(self.format_tool_instructions(tool_name, tool, instructions))\n",
        "\n",
        "    def sys_prompt(self, sys_prompt: str):\n",
        "        self.memory.append(\n",
        "            {\n",
        "                'role': 'system',\n",
        "                'content': sys_prompt\n",
        "            }\n",
        "        )\n",
        "        self.log.append({\n",
        "            'time': get_time(),\n",
        "            'action': 'sys_prompt',\n",
        "            'prompt': sys_prompt,\n",
        "            'other': {}\n",
        "        })\n",
        "\n",
        "    def chat(self, prompt: str):\n",
        "        self.memory.append(\n",
        "            {\n",
        "                'role': 'user',\n",
        "                'content': prompt\n",
        "            }\n",
        "        )\n",
        "\n",
        "        start_time = get_time()\n",
        "        user_content = ''\n",
        "\n",
        "        self.log.append({\n",
        "            'time': start_time,\n",
        "            'action': 'chat',\n",
        "            'prompt': prompt,\n",
        "            'other': {}\n",
        "        })\n",
        "\n",
        "        while True:\n",
        "            content = ''\n",
        "            stream: ChatResponse = self.client.chat(model=self.model,messages=self.memory, stream=True)\n",
        "\n",
        "            for chunk in stream:\n",
        "                content += chunk.message.content\n",
        "                tool_match = re.search(r'<call tool>(.*?)</call tool>', content)\n",
        "                if tool_match:\n",
        "                    tool_call = tool_match.group(1)\n",
        "                    break  # Stop stream when tool use is detected\n",
        "\n",
        "            user_content += re.sub(r\"<call tool>.*?</call tool>\", \"\", content).strip()\n",
        "            self.memory.append({'role': 'assistant', 'content': content})\n",
        "\n",
        "            if tool_match:\n",
        "                tool_name, *params = self._extract_tool_call(tool_call)\n",
        "\n",
        "                # Handle commas inside strings\n",
        "                joined_params = ','.join(params)\n",
        "                params = re.split(r',(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', joined_params)\n",
        "\n",
        "                # Inject tool result back into memory\n",
        "                try:\n",
        "                    tool_result = f\"<tool return result>{self.tools[tool_name]['tool'](*params)}</tool return result>\"\n",
        "                except Exception as e:\n",
        "                    if tool_name not in self.tools:\n",
        "                        tool_result = f\"<tool return result>Error: Tool not defined.</tool return result>\"\n",
        "                    else:\n",
        "                        tool_result = f\"<tool return result>Error: {type(e)}</tool return result>\"\n",
        "\n",
        "                self.log.append({\n",
        "                    'time': get_time(),\n",
        "                    'action': 'tool',\n",
        "                    'prompt': tool_call,\n",
        "                    'other': {\n",
        "                        'tool_result': tool_result,\n",
        "                        'tool_name': tool_name,\n",
        "                        'params': params,\n",
        "                    }\n",
        "                })\n",
        "                self.sys_prompt(tool_result)\n",
        "            else:\n",
        "                break  # No more tool calls, exit loop\n",
        "        end_time = get_time()\n",
        "\n",
        "        self.log.append({\n",
        "            'time': end_time,\n",
        "            'action': 'chat_end',\n",
        "            'prompt': prompt,\n",
        "            'other': {\n",
        "                'total_duration': time_difference_in_ns(start_time, end_time)\n",
        "            }\n",
        "        })\n",
        "\n",
        "        return user_content\n",
        "\n",
        "    def get_memory(self):\n",
        "        return self.memory\n",
        "\n",
        "    def get_tools(self):\n",
        "        return self.tools\n",
        "\n",
        "    def set_memory(self, memory):\n",
        "        self.memory = memory\n",
        "\n",
        "    def get_log(self):\n",
        "        return self.log\n",
        "\n",
        "    def _add_to_log(self, time, action, prompt, other):\n",
        "        log_entry = {\n",
        "            'time': time,\n",
        "            'action': action,\n",
        "            'prompt': prompt,\n",
        "            'other': other\n",
        "        }\n",
        "        self.log.append(log_entry)\n",
        "\n",
        "    def _extract_tool_call(self, tool_call: str):\n",
        "        \"\"\"\n",
        "        Extract tool name and parameters.\n",
        "        Example Input: 'fibonnaci(5)'\n",
        "        Output: ('fibonacci', ('5',))\n",
        "        \"\"\"\n",
        "        tool_match = re.match(r'(\\w+)\\((.*?)\\)', tool_call.strip())\n",
        "        if tool_match:\n",
        "            tool_name = tool_match.group(1)\n",
        "            params = tuple(map(str.strip, tool_match.group(2).split(',')))\n",
        "            return tool_name, *params\n",
        "        return tool_call, ()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OqaI5JTBSqLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_symptom_info(species: str, limit: int = 5000) -> str:\n",
        "    '''\n",
        "    Retrieve symptom information for a given virus species by searching:\n",
        "    1. Wikipedia\n",
        "    2. ICTV (International Committee on Taxonomy of Viruses)\n",
        "    3. Scientific literature (e.g., PubMed)\n",
        "    If no information is found, indicate that no symptom data is available.\n",
        "    '''\n",
        "    # Define search queries for different sources\n",
        "    queries = [\n",
        "        f\"{species} symptoms site:en.wikipedia.org\",\n",
        "        f\"{species} symptoms site:ictv.global\",\n",
        "        f\"{species} symptoms site:pubmed.ncbi.nlm.nih.gov\"\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        try:\n",
        "            # Perform a Google search and retrieve the first result\n",
        "            search_results = search(query, num=1, stop=1, pause=2)\n",
        "            for url in search_results:\n",
        "                # Fetch the content of the URL\n",
        "                response = requests.get(url)\n",
        "                if response.status_code == 200:\n",
        "                    # Parse the webpage content\n",
        "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "                    paragraphs = soup.find_all('p')\n",
        "                    content = ' '.join([para.get_text() for para in paragraphs])\n",
        "                    return content[1:2500] + \"\"\"Remember that you are an AI agent designed to determine disease symptoms. Make sure you respond in the following format: ```\n",
        "- symptom1: severity1\n",
        "- symptom2: severity2\n",
        "...\n",
        "\n",
        "Use a 0 to 1 severity scale:\n",
        "- 0 = symptom not present\n",
        "- 0.33 ≈ mild presence\n",
        "- 0.67 ≈ moderate presence\n",
        "- 1 = severe symptom\n",
        "Only use the number. Do not include the description.\n",
        "\n",
        "If a symptom is very specific, ignore it. If a symptom is more than a few words or describes in great detail, just use a simple one-word description. USE ONE WORD DESCRIPTIONS WHENEVER POSSIBLE\n",
        "```\"\"\"\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while searching with query '{query}': {e}\")\n",
        "            continue\n",
        "\n",
        "    # If no information is found\n",
        "    return f\"No symptom information found for '{species}'. Treat this virus as having no known symptoms.\"\n",
        "\n",
        "def extract_symptom_dict(text: str) -> dict:\n",
        "    symptom_dict = {}\n",
        "\n",
        "    # Find lines with a colon, typically symptoms\n",
        "    lines = text.splitlines()\n",
        "    for line in lines:\n",
        "        if ':' in line:\n",
        "            try:\n",
        "                # Split at the first colon\n",
        "                symptom, severity = line.split(':', 1)\n",
        "                symptom = symptom.strip().lstrip(\"- \").strip()\n",
        "\n",
        "                # Extract the first float number from severity string\n",
        "                match = re.search(r\"\\d*\\.?\\d+\", severity)\n",
        "                if match:\n",
        "                    severity_score = float(match.group())\n",
        "                    symptom_dict[symptom] = severity_score\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "    return symptom_dict\n"
      ],
      "metadata": {
        "id": "FGckZUJHZa70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disease_classifier = Agent('phi4')\n",
        "\n",
        "disease_classifier.add_tool(\"get_symptom_info\", get_symptom_info, \"Retrieves the symptom information from various websites for a given virus species.\")\n",
        "disease_classifier.sys_prompt(\"\"\"\n",
        "You are an expert virus-to-symptom assistant. Given a virus species name, your task is to extract a list of symptoms and their severity based on available information.\n",
        "\n",
        "You should call the tool `get_symptom_info` to search for it before coming to a conclusion.\n",
        "\n",
        "The user will give you the name of a virus. When responding, always return your output in this format:\n",
        "\n",
        "```\n",
        "- symptom1: severity1\n",
        "- symptom2: severity2\n",
        "...\n",
        "```\n",
        "\n",
        "Use a 0 to 1 severity scale:\n",
        "- 0 = symptom not present\n",
        "- 0.33 ≈ mild presence\n",
        "- 0.67 ≈ moderate presence\n",
        "- 1 = severe symptom\n",
        "Only use the number. Do not include the description.\n",
        "\n",
        "If no symptoms are found or the virus is asymptomatic, return:\n",
        "```\n",
        "```\n",
        "\n",
        "Be concise and do NOT include unnecessary explanations. Focus only on the symptoms and severity and use ONLY common medical terms to describe symptoms.\n",
        "\n",
        "ALWAYS return your output in this format. You MUST use the following format:\n",
        "```\n",
        "- symptom1: severity1\n",
        "- symptom2: severity2\n",
        "...\n",
        "```\n",
        "\n",
        "If a symptom is very specific, ignore it. If a symptom is more than a few words or describes in great detail, just use a simple one-word description (a precise medical term is preferable).\n",
        "Make sure you use the tool!\"\"\")\n",
        "\n",
        "classifier_memory = disease_classifier.get_memory()\n",
        "classifier_tools = disease_classifier.get_tools()\n",
        "\n",
        "print(classifier_memory)\n",
        "print(classifier_tools)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0DtuES8ZcnB",
        "outputId": "c9237602-c194-41b7-d67c-3126590c8992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': 'You have been given access to the tool \"get_symptom_info(species, limit=5000)\". Retrieves the symptom information from various websites for a given virus species.\\n    Please call this function by using the following format: <call tool>get_symptom_info(species, limit=5000)</call tool>'}, {'role': 'system', 'content': '\\nYou are an expert virus-to-symptom assistant. Given a virus species name, your task is to extract a list of symptoms and their severity based on available information.\\n\\nYou should call the tool `get_symptom_info` to search for it before coming to a conclusion.\\n\\nThe user will give you the name of a virus. When responding, always return your output in this format:\\n\\n```\\n- symptom1: severity1\\n- symptom2: severity2\\n...\\n```\\n\\nUse a 0 to 1 severity scale:\\n- 0 = symptom not present\\n- 0.33 ≈ mild presence\\n- 0.67 ≈ moderate presence\\n- 1 = severe symptom\\nOnly use the number. Do not include the description.\\n\\nIf no symptoms are found or the virus is asymptomatic, return:\\n```\\n```\\n\\nBe concise and do NOT include unnecessary explanations. Focus only on the symptoms and severity and use ONLY common medical terms to describe symptoms.\\n\\nALWAYS return your output in this format. You MUST use the following format:\\n```\\n- symptom1: severity1\\n- symptom2: severity2\\n...\\n```\\n\\nIf a symptom is very specific, ignore it. If a symptom is more than a few words or describes in great detail, just use a simple one-word description (a precise medical term is preferable).\\nMake sure you use the tool!'}]\n",
            "{'get_symptom_info': {'tool': <function get_symptom_info at 0x7fa2cd4b4af0>, 'instructions': 'Retrieves the symptom information from various websites for a given virus species.'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing = Agent('phi4')\n",
        "\n",
        "testing.set_memory(classifier_memory)\n",
        "testing.tools = classifier_tools\n",
        "\n",
        "chat_response = testing.chat(\"Ebola\")\n",
        "print(chat_response)\n",
        "print(extract_symptom_dict(chat_response))\n",
        "[print(item) for item in testing.log]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0Uk5_PCdsW8",
        "outputId": "ea4f2236-52a8-4027-e95b-e3a032992a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- fever: 1\n",
            "- headache: 0.67\n",
            "- muscle pain: 0.67\n",
            "- sore throat: 0.33\n",
            "- vomiting: 0.67\n",
            "- diarrhea: 0.67\n",
            "- rash: 0.67\n",
            "- decreased liver function: 0.67\n",
            "- decreased kidney function: 0.67\n",
            "- bleeding (internal/external): 1\n",
            "{'fever': 1.0, 'headache': 0.67, 'muscle pain': 0.67, 'sore throat': 0.33, 'vomiting': 0.67, 'diarrhea': 0.67, 'rash': 0.67, 'decreased liver function': 0.67, 'decreased kidney function': 0.67, 'bleeding (internal/external)': 1.0}\n",
            "{'time': '2025-03-29T22:03:39.877710Z', 'action': '__init__', 'prompt': 'phi4', 'other': {}}\n",
            "{'time': '2025-03-29T22:03:39.877821Z', 'action': 'chat', 'prompt': 'Ebola', 'other': {}}\n",
            "{'time': '2025-03-29T22:03:49.773022Z', 'action': 'tool', 'prompt': 'get_symptom_info(Ebola, limit=5000)', 'other': {'tool_result': '<tool return result> Ebola, also known as Ebola virus disease (EVD) and Ebola hemorrhagic fever (EHF), is a viral hemorrhagic fever in humans and other primates, caused by ebolaviruses.[1] Symptoms typically start anywhere between two days and three weeks after infection.[3] The first symptoms are usually fever, sore throat, muscle pain, and headaches.[1] These are usually followed by vomiting, diarrhoea, rash and decreased liver and kidney function,[1] at which point some people begin to bleed both internally and externally.[1] It kills between 25% and 90% of those infected – about 50% on average.[1] Death is often due to shock from fluid loss, and typically occurs between six and 16 days after the first symptoms appear.[2] Early treatment of symptoms increases the survival rate considerably compared to late start.[4] An Ebola vaccine was approved by the US FDA in December 2019.\\n The virus spreads through direct contact with body fluids, such as blood from infected humans or other animals,[1] or from contact with items that have recently been contaminated with infected body fluids.[1] There have been no documented cases, either in nature or under laboratory conditions, of spread through the air between humans or other primates.[5] After recovering from Ebola, semen or breast milk may continue to carry the virus for anywhere between several weeks to several months.[1][6][7] Fruit bats are believed to be the normal carrier in nature; they are able to spread the virus without being affected by it.[1] The symptoms of Ebola may resemble those of several other diseases, including malaria, cholera, typhoid fever, meningitis and other viral hemorrhagic fevers.[1] Diagnosis is confirmed by testing blood samples for the presence of viral RNA, viral antibodies or the virus itself.[1][8]\\n Control of outbreaks requires coordinated medical services and community engagement,[1] including rapid detection, contact tracing of those exposed, quick access to laboratory services, care for those infected, and proper disposal of the dead through cremation or burial.[1][9] Prevention measures involve wearing proper protective clothing and washing hands when in close proximity to patients and while handling potentially infected bushmeat, as well as thoroughly cooking bushmeat.[1] An Ebola vaccine was approved by the US FDA in December 2019.[10] While there is no approved treatment for Ebola as of 2019[update],[11] two treatments (atoltivimab/maftivimab/odesivimab and ansuvimab) are associated with Remember that you are an AI agent designed to determine disease symptoms. Make sure you respond in the following format: ```\\n- symptom1: severity1\\n- symptom2: severity2\\n...\\n\\nUse a 0 to 1 severity scale:\\n- 0 = symptom not present\\n- 0.33 ≈ mild presence\\n- 0.67 ≈ moderate presence\\n- 1 = severe symptom\\nOnly use the number. Do not include the description.\\n\\nIf a symptom is very specific, ignore it. If a symptom is more than a few words or describes in great detail, just use a simple one-word description. USE ONE WORD DESCRIPTIONS WHENEVER POSSIBLE\\n```</tool return result>', 'tool_name': 'get_symptom_info', 'params': ['Ebola', 'limit=5000']}}\n",
            "{'time': '2025-03-29T22:03:49.773057Z', 'action': 'sys_prompt', 'prompt': '<tool return result> Ebola, also known as Ebola virus disease (EVD) and Ebola hemorrhagic fever (EHF), is a viral hemorrhagic fever in humans and other primates, caused by ebolaviruses.[1] Symptoms typically start anywhere between two days and three weeks after infection.[3] The first symptoms are usually fever, sore throat, muscle pain, and headaches.[1] These are usually followed by vomiting, diarrhoea, rash and decreased liver and kidney function,[1] at which point some people begin to bleed both internally and externally.[1] It kills between 25% and 90% of those infected – about 50% on average.[1] Death is often due to shock from fluid loss, and typically occurs between six and 16 days after the first symptoms appear.[2] Early treatment of symptoms increases the survival rate considerably compared to late start.[4] An Ebola vaccine was approved by the US FDA in December 2019.\\n The virus spreads through direct contact with body fluids, such as blood from infected humans or other animals,[1] or from contact with items that have recently been contaminated with infected body fluids.[1] There have been no documented cases, either in nature or under laboratory conditions, of spread through the air between humans or other primates.[5] After recovering from Ebola, semen or breast milk may continue to carry the virus for anywhere between several weeks to several months.[1][6][7] Fruit bats are believed to be the normal carrier in nature; they are able to spread the virus without being affected by it.[1] The symptoms of Ebola may resemble those of several other diseases, including malaria, cholera, typhoid fever, meningitis and other viral hemorrhagic fevers.[1] Diagnosis is confirmed by testing blood samples for the presence of viral RNA, viral antibodies or the virus itself.[1][8]\\n Control of outbreaks requires coordinated medical services and community engagement,[1] including rapid detection, contact tracing of those exposed, quick access to laboratory services, care for those infected, and proper disposal of the dead through cremation or burial.[1][9] Prevention measures involve wearing proper protective clothing and washing hands when in close proximity to patients and while handling potentially infected bushmeat, as well as thoroughly cooking bushmeat.[1] An Ebola vaccine was approved by the US FDA in December 2019.[10] While there is no approved treatment for Ebola as of 2019[update],[11] two treatments (atoltivimab/maftivimab/odesivimab and ansuvimab) are associated with Remember that you are an AI agent designed to determine disease symptoms. Make sure you respond in the following format: ```\\n- symptom1: severity1\\n- symptom2: severity2\\n...\\n\\nUse a 0 to 1 severity scale:\\n- 0 = symptom not present\\n- 0.33 ≈ mild presence\\n- 0.67 ≈ moderate presence\\n- 1 = severe symptom\\nOnly use the number. Do not include the description.\\n\\nIf a symptom is very specific, ignore it. If a symptom is more than a few words or describes in great detail, just use a simple one-word description. USE ONE WORD DESCRIPTIONS WHENEVER POSSIBLE\\n```</tool return result>', 'other': {}}\n",
            "{'time': '2025-03-29T22:03:51.623791Z', 'action': 'chat_end', 'prompt': 'Ebola', 'other': {'total_duration': 11745970000}}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_df = filtered_df.copy()\n",
        "\n",
        "print(training_df.head())\n",
        "\n",
        "symptom_data = []\n",
        "all_symptoms = set()\n",
        "\n",
        "for _, row in tqdm(training_df.iterrows(), total=len(training_df)):\n",
        "    species = row['Organism_Name']\n",
        "\n",
        "    # Use the agent to get a response\n",
        "    try:\n",
        "        disease_classifier_copy = Agent('phi4')\n",
        "        disease_classifier_copy.set_memory(classifier_memory)\n",
        "        disease_classifier_copy.tools = classifier_tools\n",
        "\n",
        "        response = disease_classifier_copy.chat(species)\n",
        "\n",
        "        symptom_dict = extract_symptom_dict(response)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Failed on {species}: {e}\")\n",
        "        symptom_dict = {}\n",
        "\n",
        "    # Track all symptoms seen so far\n",
        "    all_symptoms.update(symptom_dict.keys())\n",
        "\n",
        "    # Add organism + its symptom dictionary\n",
        "    symptom_data.append({\n",
        "        \"Organism_Name\": species,\n",
        "        **symptom_dict\n",
        "    })\n",
        "\n",
        "# Create the symptom DataFrame\n",
        "symptom_df = pd.DataFrame(symptom_data)\n",
        "\n",
        "# Fill missing symptoms with 0 (not mentioned)\n",
        "for symptom in all_symptoms:\n",
        "    if symptom not in symptom_df.columns:\n",
        "        symptom_df[symptom] = 0\n",
        "\n",
        "# Optional: reorder columns\n",
        "symptom_columns = sorted(list(all_symptoms))\n",
        "final_df = symptom_df[['Organism_Name'] + symptom_columns]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrJkjWqHlUh-",
        "outputId": "91890154-3862-4409-ea02-13ea448edb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Assembly               Organism_Name                     Species  \\\n",
            "0  GCF_029888495.1                  Yezo virus    Orthonairovirus yezoense   \n",
            "1  GCF_029888155.1            Beiji nairovirus            Beiji nairovirus   \n",
            "2  GCF_029888075.1              Songling virus              Songling virus   \n",
            "3  GCF_018595055.1  Dar es Salaam virus TZ-189  Tanzavirus daressalaamense   \n",
            "4  GCF_013086615.1                 Cocle virus       Phlebovirus cocleense   \n",
            "\n",
            "             Genus         Family  \n",
            "0  Orthonairovirus   Nairoviridae  \n",
            "1  Orthonairovirus   Nairoviridae  \n",
            "2  Orthonairovirus   Nairoviridae  \n",
            "3       Tanzavirus  Phenuiviridae  \n",
            "4      Phlebovirus  Phenuiviridae  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 203/203 [07:59<00:00,  2.36s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(final_df.head())\n",
        "\n",
        "# display influenza symptoms (testcase)\n",
        "\n",
        "final_df.fillna(0, inplace=True)\n",
        "\n",
        "row = final_df.loc[final_df['Organism_Name'] == 'Bundibugyo ebolavirus']\n",
        "\n",
        "if not row.empty:\n",
        "    for column, value in row.iloc[0].items():\n",
        "        if value != 0:\n",
        "          print(f\"{column}: {value}\")\n",
        "else:\n",
        "    print(\"No match found.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W1i8z_RmSOB",
        "outputId": "dbdd90f4-da2f-43bc-a1b3-3204684256c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Organism_Name: Bundibugyo ebolavirus\n",
            "diarrhea: 1.0\n",
            "fever: 1.0\n",
            "headache: 1.0\n",
            "muscle pain: 1.0\n",
            "rash: 0.67\n",
            "vomiting: 1.0\n",
            "weakness: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = symptom_df.merge(\n",
        "    training_df[[\"Organism_Name\", \"Assembly\"]],\n",
        "    on=\"Organism_Name\",\n",
        "    how=\"left\"  # or \"inner\" if you only want overlapping ones\n",
        ")\n",
        "\n",
        "final_df.fillna(0, inplace=True)\n",
        "print(final_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCte-rIlrl5e",
        "outputId": "1aae2218-7293-4751-a7b5-24d0154587a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Organism_Name  fever  headache  dizziness  blurred vision  \\\n",
            "0                    Yezo virus   0.67      0.33       0.33            0.33   \n",
            "1              Beiji nairovirus   0.33      0.00       0.00            0.00   \n",
            "2                Songling virus   0.67      0.33       0.00            0.00   \n",
            "3    Dar es Salaam virus TZ-189   0.00      0.00       0.00            0.00   \n",
            "4                   Cocle virus   0.33      0.00       0.00            0.00   \n",
            "..                          ...    ...       ...        ...             ...   \n",
            "198      Human mastadenovirus C   0.33      0.00       0.00            0.00   \n",
            "199       Human erythrovirus V9   0.33      0.00       0.00            0.00   \n",
            "200    Human gammaherpesvirus 8   0.00      0.00       0.00            0.00   \n",
            "201           Influenza B virus   0.00      0.00       0.00            0.00   \n",
            "202           Influenza C virus   0.00      0.00       0.00            0.00   \n",
            "\n",
            "     shortness of breath  fatigue  arthralgia  thrombocytopenia  leukopenia  \\\n",
            "0                   0.33     0.33        0.33              0.67        0.67   \n",
            "1                   0.67     0.00        0.00              0.00        0.00   \n",
            "2                   0.00     0.33        0.00              0.00        0.00   \n",
            "3                   0.00     0.00        0.00              0.00        0.00   \n",
            "4                   0.33     0.00        0.00              0.00        0.00   \n",
            "..                   ...      ...         ...               ...         ...   \n",
            "198                 0.33     0.00        0.00              0.00        0.00   \n",
            "199                 0.00     0.00        0.00              0.00        0.00   \n",
            "200                 0.00     0.00        0.00              0.00        0.00   \n",
            "201                 0.00     0.00        0.00              0.00        0.00   \n",
            "202                 0.00     0.00        0.00              0.00        0.00   \n",
            "\n",
            "     ...  General malaise  irritability  Runny/Stuffy Nose  Sore Throat  \\\n",
            "0    ...              0.0           0.0                0.0          0.0   \n",
            "1    ...              0.0           0.0                0.0          0.0   \n",
            "2    ...              0.0           0.0                0.0          0.0   \n",
            "3    ...              0.0           0.0                0.0          0.0   \n",
            "4    ...              0.0           0.0                0.0          0.0   \n",
            "..   ...              ...           ...                ...          ...   \n",
            "198  ...              0.0           0.0                0.0          0.0   \n",
            "199  ...              0.0           0.0                0.0          0.0   \n",
            "200  ...              0.0           0.0                0.0          0.0   \n",
            "201  ...              0.0           0.0                0.0          0.0   \n",
            "202  ...              0.0           0.0                0.0          0.0   \n",
            "\n",
            "     Shortness of Breath  cold-like symptoms  Skin rash  \\\n",
            "0                    0.0                0.00       0.00   \n",
            "1                    0.0                0.00       0.00   \n",
            "2                    0.0                0.00       0.00   \n",
            "3                    0.0                0.00       0.00   \n",
            "4                    0.0                0.00       0.00   \n",
            "..                   ...                 ...        ...   \n",
            "198                  0.0                0.00       0.00   \n",
            "199                  0.0                0.33       0.00   \n",
            "200                  0.0                0.00       0.33   \n",
            "201                  0.0                0.00       0.00   \n",
            "202                  0.0                0.00       0.00   \n",
            "\n",
            "     Lymph node enlargement  Muscle aches         Assembly  \n",
            "0                      0.00          0.00  GCF_029888495.1  \n",
            "1                      0.00          0.00  GCF_029888155.1  \n",
            "2                      0.00          0.00  GCF_029888075.1  \n",
            "3                      0.00          0.00  GCF_018595055.1  \n",
            "4                      0.00          0.00  GCF_013086615.1  \n",
            "..                      ...           ...              ...  \n",
            "198                    0.00          0.00  GCF_000845085.1  \n",
            "199                    0.00          0.00  GCF_000841965.1  \n",
            "200                    0.67          0.00  GCF_000838265.1  \n",
            "201                    0.00          0.67  GCA_049040715.1  \n",
            "202                    0.00          0.33  GCA_048212775.1  \n",
            "\n",
            "[203 rows x 146 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
        "\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 0) Make sure final_df is defined or loaded here.\n",
        "# final_df = ...\n",
        "# ------------------------------------------------\n",
        "\n",
        "non_numeric = ['Organism_Name', 'Assembly']\n",
        "numeric_cols = [col for col in final_df.columns if col not in non_numeric]\n",
        "\n",
        "lowercase_map = {}\n",
        "for col in numeric_cols:\n",
        "    key = col.lower()\n",
        "    lowercase_map.setdefault(key, []).append(col)\n",
        "\n",
        "agg_data = {}\n",
        "for key, cols in lowercase_map.items():\n",
        "    agg_data[key] = final_df[cols].sum(axis=1)\n",
        "\n",
        "df_agg = pd.concat([final_df[non_numeric], pd.DataFrame(agg_data)], axis=1)\n",
        "\n",
        "def load_genome_from_assembly(assembly):\n",
        "    filepath = os.path.join(\"op\", \"sequences\", assembly + \".txt\")\n",
        "    try:\n",
        "        with open(filepath, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        return lines[1].strip() if len(lines) > 1 else \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {filepath}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "df_agg[\"Genome\"] = df_agg[\"Assembly\"].apply(load_genome_from_assembly)\n",
        "\n",
        "print(\"Aggregated DataFrame with Genome column:\")\n",
        "print(df_agg.head())\n",
        "\n",
        "symptom_cols = list(agg_data.keys())\n",
        "symptom_tensor = torch.tensor(df_agg[symptom_cols].values, dtype=torch.float)\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 1) Load BOTH the tokenizer and model with trust_remote_code=True\n",
        "#    so DNABERT's custom code + config are used properly.\n",
        "# ------------------------------------------------\n",
        "MODEL_NAME = \"armheb/DNA_bert_6\"\n",
        "\n",
        "# Load configuration, tokenizer, and model (this model does not require trust_remote_code)\n",
        "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForMaskedLM.from_pretrained(MODEL_NAME, config=config)\n",
        "model.eval()\n",
        "\n",
        "def compute_transformer_embedding(sequence, max_length=512):\n",
        "    \"\"\"\n",
        "    Convert a (nucleotide) sequence into a transformer embedding.\n",
        "    For very long sequences, consider chunking or specialized handling\n",
        "    because BERT-like models typically have a 512-token limit.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        sequence,\n",
        "        return_tensors='pt',\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        padding='max_length'\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "        # Use the last hidden state from hidden_states tuple:\n",
        "        last_hidden_state = outputs.hidden_states[-1]  # [batch_size, seq_len, hidden_size]\n",
        "        embedding = last_hidden_state.mean(dim=1).squeeze(0)  # [hidden_size]\n",
        "    return embedding\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 2) Precompute embeddings for all known genomes\n",
        "# ------------------------------------------------\n",
        "embeddings = []\n",
        "for seq in df_agg[\"Genome\"]:\n",
        "    seq = seq.strip()\n",
        "    if seq:\n",
        "        emb = compute_transformer_embedding(seq)\n",
        "    else:\n",
        "        emb = torch.zeros(model.config.hidden_size)\n",
        "    embeddings.append(emb)\n",
        "\n",
        "genome_embeddings = torch.stack(embeddings, dim=0)  # [num_genomes, hidden_size]\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 3) Lookup function for the nearest embedding\n",
        "# ------------------------------------------------\n",
        "def get_closest_organism(input_genome):\n",
        "    # Embed user input\n",
        "    input_embedding = compute_transformer_embedding(input_genome)\n",
        "    input_embedding_2d = input_embedding.unsqueeze(0)  # [1, hidden_size]\n",
        "\n",
        "    # Cosine similarity\n",
        "    similarities = F.cosine_similarity(input_embedding_2d, genome_embeddings, dim=1)\n",
        "    best_idx = torch.argmax(similarities).item()\n",
        "\n",
        "    organism = df_agg.loc[best_idx, 'Organism_Name']\n",
        "    guess_tensor = symptom_tensor[best_idx]\n",
        "    return organism, guess_tensor"
      ],
      "metadata": {
        "id": "g0fJzy_Tuo6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0922deeb-8b0a-48a7-9ea8-fc8c4570e3bd"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated DataFrame with Genome column:\n",
            "                Organism_Name         Assembly  fever  headache  dizziness  \\\n",
            "0                  Yezo virus  GCF_029888495.1   0.67      0.33       0.33   \n",
            "1            Beiji nairovirus  GCF_029888155.1   0.33      0.00       0.00   \n",
            "2              Songling virus  GCF_029888075.1   0.67      0.33       0.00   \n",
            "3  Dar es Salaam virus TZ-189  GCF_018595055.1   0.67      0.33       0.00   \n",
            "4                 Cocle virus  GCF_013086615.1   0.33      0.00       0.00   \n",
            "\n",
            "   blurred vision  shortness of breath  fatigue  arthralgia  thrombocytopenia  \\\n",
            "0            0.33                 0.33     0.33        0.33              0.67   \n",
            "1            0.00                 0.67     0.00        0.00              0.00   \n",
            "2            0.00                 0.00     0.33        0.00              0.00   \n",
            "3            0.00                 0.00     0.33        0.00              0.00   \n",
            "4            0.00                 0.33     0.00        0.00              0.00   \n",
            "\n",
            "   ...  weight loss  blister  unexplained hemorrhage  sneezing  \\\n",
            "0  ...          0.0      0.0                     0.0       0.0   \n",
            "1  ...          0.0      0.0                     0.0       0.0   \n",
            "2  ...          0.0      0.0                     0.0       0.0   \n",
            "3  ...          0.0      0.0                     0.0       0.0   \n",
            "4  ...          0.0      0.0                     0.0       0.0   \n",
            "\n",
            "   general malaise  irritability  cold-like symptoms  skin rash  \\\n",
            "0              0.0           0.0                 0.0        0.0   \n",
            "1              0.0           0.0                 0.0        0.0   \n",
            "2              0.0           0.0                 0.0        0.0   \n",
            "3              0.0           0.0                 0.0        0.0   \n",
            "4              0.0           0.0                 0.0        0.0   \n",
            "\n",
            "   lymph node enlargement                                             Genome  \n",
            "0                     0.0  TCTCAAAGACATCTATCCTGCAATCCCCCCACTAAGGCTAACCTCC...  \n",
            "1                     0.0  TCTCGAAGATATCTATCCCCCCGGTTTCCTAAGACTTTTCGTTAAA...  \n",
            "2                     0.0  TCTCAAAGATATATATCCTGCACACCCAAAACACTATTGCACTCAC...  \n",
            "3                     0.0  CATCTATCAACATGTCAGTGTCCGCAATACAGGAAAGCAACATTGC...  \n",
            "4                     0.0  ACACAAAGAAGTCCCAATAACAATGGAATCTTTACTAAGAAAGCAA...  \n",
            "\n",
            "[5 rows x 119 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at armheb/DNA_bert_6 were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------\n",
        "# 4) Example usage\n",
        "# ------------------------------------------------\n",
        "input_genome = (\n",
        "    \"ATGAATATAAATCCTTATTTTCTCTTCATAGATGTGCCAGTACAGGCAGCAATTTCAACAACATTCCCATACACTGGTGTTCCCCCTTATTCCCATGGAACAGGAACAGGTTACACAATAGACACCGTGATCAGAACGCATGAGTACTCAAACAAGGGGAAACAGTACATTTCTGATGTTACAGGATGCACAATGGTGGATCCAACAAATGGACCATTACCCGAAGATAATGAGCCGAGTGCCTATGCGCAATTAGATTGCGTTTTAGAGGCTTTGGATAGAATGGATGAAGAACACCCAGGTCTTTTTCAAGCAGCCTCACAGAATGCTATGGAGGCCCTAATGGTCACAACTGTAGACAAATTAACCCAGGGGAGACAAACTTTTGATTGGACAGTATGCAGAAACCAACCTGCTGCAACGGCACTGAATACAACAATAACCTCTTTTAGGTTGAATGATTTAAATGGAGCCGACAAAGGTGGATTAATACCTTTTTGCCAGGATATCATTGATTCATTAGACAGACCTGAAATGACTTTCTTCTCAGTAAAGAATATAAAGAAAAAATTGCCTGCCAAAAACAGAAAGGGTTTCCTCATAAAGAGGATACCAATGAAGGTAAAAGACAAAATAACCAAAGTGGAATACATCAAAAGAGCATTATCATTAAACACAATGACAAAAGACGCTGAAAGAGGCAAACTGAAAAGAAGAGCGATTGCCACTGCTGGAATACAAATAAGAGGGTTTGTATTAGTAGTTGAAAACTTGGCTAAAAATATATGTGAAAATCTAGAACAAAGTGGTTTACCAGTAGGTGGAAACGAGAAGAAAGCCAAACTGTCAAATGCAGTGGCCAAAATGCTCAGTAACTGCCCACCAGGAGGGATTAGCATGACAGTAACAGGAGACAATACAAAATGGAATGAATGTTTAAACCCAAGGATCTTTTTGGCCATGACCGAAAGAATAACCAGAGACAGCCCAGTTTGGTTCAGGGATTTTTGTAGTATAGCACCGGTCCTGTTCTCCAATAAGATAGCAAGATTGGGGAAAGGATTCATGATAACAAGCAAAACAAAAAGACTAAAGGCCCAAATACCTTGTCCTGATCTGTTTAGTATACCATTAGAAAGATATAATGAAGAAACAAGGGCAAAATTGAAGAAGCTAAAACCATTCTTCAATGAAGAAGGAACTGCATCTTTGTCACCTGGGATGATGATGGGAATGTTTAATATGCTATCTACCGTATTGGGAGTAGCTGCACTAGGTATCAAGAACATTGGAAACAAAGAATACCTATGGGATGGACTGCAATCTTCTGATGATTTTGCTCTATTTGTTAATGCAAAGGATGAAGAAACATGTATGGAAGGAATAAACGACTTTTACCGAACATGTAAATTATTGGGAATAAACATGAGCAAAAAGAAAAGTTACTGTAATGAGACTGGAATGTTTGAATTTACAAGCATGTTCTACAGAGATGGATTTGTATCTAATTTTGCAATGGAACTCCCTTCGTTTGGGGTTGCTGGAGTAAATGAATCAGCAGATATGGCAATAGGAATGACAATAATAAAGAACAACATGATCAACAATGGAATGGGTCCAGCAACAGCACAAACAGCCATACAGCTATTCATAGCTGATTATAGATACACCTACAAATGCCACAGGGGAGATTCCAAAGTAGAAGGAAAGAGAATGAAAATCATAAAGGAGTTATGGGAAAACACTAAAGGAAGAGATGGTCTATTAGTAGCAGATGGTGGGCCCAACATTTACAATTTGAGAAACTTGCATATCCCAGAAATAGTATTGAAGTATAATCTAATGGACCCTGAATACAAAGGGCGATTACTTCATCCTCAAAATCCCTTTGTGGGACATTTGTCTATTGAGGGCATCAAAGAGGCAGACATAACTCCAGCACATGGTCCAGTAAAGAAAATGGACTACGATGCAGTGTCTGGAACTCATAGTTGGAGAACCAAAAGAAACAGATCTATACTAAACACTGATCAGAGGAACATGATTCTTGAGGAACAATGCTACGCTAAATGTTGCAACCTATTTGAGGCCTGTTTTAACAGTGCATCATACAGGAAGCCAGTGGGTCAACATAGCATGCTTGAGGCTATGGCCCACAGATTAAGAATGGATGCACGATTAGATTATGAATCAGGGAGAATGTCAAAAGATGATTTTGAGAAAGCAATGGCTCACCTTGGTGAGATTGGGTACATATAA\"\n",
        ")\n",
        "\n",
        "try:\n",
        "    organism, guess = get_closest_organism(input_genome)\n",
        "    for column in df_agg.columns:\n",
        "      print(column, end=\", \")\n",
        "    print()\n",
        "    print(\"Symptom Tensor Row:\", guess.tolist())\n",
        "except ValueError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY1yHM7QBJY8",
        "outputId": "7481ff9f-fe92-4685-b85b-813496c1c53d"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Organism_Name, Assembly, fever, headache, dizziness, blurred vision, shortness of breath, fatigue, arthralgia, thrombocytopenia, leukopenia, lymphocytopenia, coagulation disorder, increased liver enzymes, cough, runny nose, stuffy nose, sore throat, wheezing, rash, muscle pain, (note, nausea, nasal congestion, malaise, myalgia, joint pain, swollen lymph nodes, runny or stuffy nose, diarrhea, respiratory symptoms, swelling, muscle ache, backache, chills, respiratory issues, symptom1, symptom2, myalgia (muscle pain), loss of taste or smell, runny/stuffy nose, vomiting, abdominal pain, thrombocytopenia (low platelet count), swollen glands, bleeding, organ failure, jaundice, dark urine, **cough**, **fever**, **runny nose**, **sore throat**, **fatigue**, wart, dysplasia, cancer, itching, warts, note, cognitive impairment, gastrointestinal distress, respiratory distress, lymphadenopathy, *note, neurological symptoms, conjunctivitis, fecal, viral, viral infection, nausea/vomiting, lesion, respiratory, cardiovascular, gastrointestinal, renal, hepatic, hematologic, neurologic, body aches, genital lesions, itching or tingling around the infection site, hydrophobia, anxiety, paralysis, dyspnea, coughing, congestion, neurological symptoms (e.g., seizures), general discomfort, confusion, agitation, drowsiness, seizures, asymptomatic, infection, lesions, weakness, runny_nose, sore_throat, shortness_of_breath, symptom, unexplained bleeding, growths, hemorrhage, malaise or fatigue, neurological signs, muscle aches, skin lesions, weight loss, blister, unexplained hemorrhage, sneezing, general malaise, irritability, cold-like symptoms, skin rash, lymph node enlargement, Genome, \n",
            "Symptom Tensor Row: [0.6700000166893005, 0.33000001311302185, 0.33000001311302185, 0.33000001311302185, 0.33000001311302185, 0.33000001311302185, 0.33000001311302185, 0.6700000166893005, 0.6700000166893005, 0.6700000166893005, 0.6700000166893005, 0.6700000166893005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    }
  ]
}